# Safety
## Jailbreak
### Attack

### Defense

### Benchmark

| Title                                                        | Author         | Publish | Year | Link                             | Source Code                                                  |
| ------------------------------------------------------------ | -------------- | ------- | ---- | -------------------------------- | ------------------------------------------------------------ |
| Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs     | Zhao Xu        | arxiv   | 2024 | https://arxiv.org/abs/2406.09324 | https://github.com/usail-hkust/Bag_of_Tricks_for_LLM_Jailbreaking |
| BELLS: A Framework Towards Future Proof Benchmarks for the Evaluation of LLM Safeguards | Diego Dorn     | arxiv   | 2024 | https://arxiv.org/abs/2406.01364 | null                                                         |
| JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models | Patrick Chao   | arxiv   | 2024 | https://arxiv.org/abs/2404.01318 | https://github.com/JailbreakBench/jailbreakbench             |
| HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal | Mantas Mazeika | arxiv   | 2024 | https://arxiv.org/abs/2402.04249 | https://github.com/centerforaisafety/HarmBench               |
| SC-Safety: A Multi-round Open-ended Question Adversarial Safety Benchmark for Large Language Models in Chinese | Liang Xu       | arxiv   | 2024 | https://arxiv.org/abs/2310.05818 | https://www.cluebenchmarks.com/                              |
| Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models | Huachuan Qiu   | arxiv   | 2024 | https://arxiv.org/abs/2307.08487 | https://github.com/qiuhuachuan/latent-jailbreak              |

### Survey

| Title                                                        | Author                 | Publish | Year | Link                             | Source Code                                           |
| ------------------------------------------------------------ | ---------------------- | ------- | ---- | -------------------------------- | ----------------------------------------------------- |
| Unique Security and Privacy Threats of Large Language Model: A Comprehensive Survey | Shang Wang             | arxiv   | 2024 | https://arxiv.org/abs/2406.07973 | [null](https://github.com/EddyLuo1232/JailBreakV_28K) |
| Exploring Vulnerabilities and Protections in Large Language Models: A Survey | Frank Weizhen Liu      | arxiv   | 2024 | https://arxiv.org/abs/2406.00240 | [null](https://github.com/EddyLuo1232/JailBreakV_28K) |
| Safeguarding Large Language Models: A Survey                 | Yi Dong                | arxiv   | 2024 | https://arxiv.org/abs/2406.02622 | null                                                  |
| Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression | Junyuan Hong           | arxiv   | 2024 | https://arxiv.org/abs/2403.15447 | null                                                  |
| Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices | Sara Abdali            | arxiv   | 2024 | https://arxiv.org/abs/2403.12503 | null                                                  |
| Breaking Down the Defenses: A Comparative Survey of Attacks on Large Language Models | Arijit Ghosh Chowdhury | arxiv   | 2024 | https://arxiv.org/abs/2403.04786 | null                                                  |
| Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey | Zhichen Dong           | arxiv   | 2024 | https://arxiv.org/abs/2402.09283 | null                                                  |
| Security and Privacy Challenges of Large Language Models: A Survey | Badhan Chandra Das     | arxiv   | 2024 | https://arxiv.org/abs/2402.00888 | null                                                  |
| Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems | Tianyu Cui             | arxiv   | 2024 | https://arxiv.org/abs/2401.05778 | null                                                  |
| TrustLLM: Trustworthiness in Large Language Models           | Lichao Sun             | arxiv   | 2024 | https://arxiv.org/abs/2401.05561 | null                                                  |
| A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly | Yifan Yao              | arxiv   | 2024 | https://arxiv.org/abs/2312.02003 | null                                                  |
| A Comprehensive Overview of Large Language Models            | Humza Naveed           | arxiv   | 2024 | https://arxiv.org/abs/2307.06435 | null                                                  |
| Safety Assessment of Chinese Large Language Models           | Hao Sun                | arxiv   | 2024 | https://arxiv.org/abs/2304.10436 | null                                                  |
| Holistic Evaluation of Language Models                       | Percy Liang            | arxiv   | 2024 | https://arxiv.org/abs/2211.09110 | null                                                  |
